{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Neural Network in Keras\n",
    "In the previous section, we built a neural network from scratch, that is, we wrote functions that perform forward-propagation and back-propagation.\n",
    "\n",
    "We will be building a neural network using the **Keras** library, which provides utilities that make the process of building a complex neural network much easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to do it...\n",
    "In this section, let's understand the process of building a model in Keras by using the same *toy dataset* that we worked on in the previous sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = np.array([[1],[2],[3],[4]])\n",
    "y = np.array([[2],[4],[6],[8]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Instantiate a model that can be called sequentially to add further layers on top of it. The `Sequential` method enables us to perform the model initialization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Add a dense layer to the model. A dense layer ensures the connection between various layers in a model. In the following code, we are connecting the input layer to the hidden layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "model.add(Dense(3, activation='relu', input_shape=(1,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We ensured that we provide the input shape to the model (we need to specify the shape of data that the model has to expect as this is the first dense layer).\n",
    "\n",
    "Additionally, we mentioned that there will be three connections made to each input (three units in the hidden layer) and also that the activation that needs to be performed in the hidden layer is the ReLu activation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Connect the hidden layer to the output layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in this dense layer, we don't need to specify the input shape, as the model would already infer the input shape from the previous layer.Â \n",
    "\n",
    "Also, given that each output is one-dimensional, our output layer has one unit and the activation that we are performing is the linear activation.\n",
    "\n",
    "The model summary can now be visualized as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 3)                 6         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 10\n",
      "Trainable params: 10\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preceding output confirms our discussion in the previous section: that there will be a total of 6 parameters in the connection from the input layer to the hidden layer (3 weights and 3 bias terms). In addition, 3 weights and 1 bias term connect the hidden layer to the output layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Extract the weight values. The order in which the weight values are presented is obtained by calling the `weights` method on top of the model, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_15/kernel:0' shape=(1, 3) dtype=float32>,\n",
       " <tf.Variable 'dense_15/bias:0' shape=(3,) dtype=float32>,\n",
       " <tf.Variable 'dense_16/kernel:0' shape=(3, 1) dtype=float32>,\n",
       " <tf.Variable 'dense_16/bias:0' shape=(1,) dtype=float32>]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "La siguiente lista generada en forma aleatoria es la que hemos empleado para inicializar la red neuronal correspondiente a nuestra implementacion a mano (scratch) en el cuaderno previo.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.22940898, 0.77437544, 0.38963628]], dtype=float32),\n",
       " array([0., 0., 0.], dtype=float32),\n",
       " array([[-0.82037127],\n",
       "        [-0.5443506 ],\n",
       "        [ 1.193303  ]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Compile the model. This ensures that we define the loss function, the optimizer (to reduce the loss) and the learning rate (corresponding to the optimizer): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import sgd\n",
    "s = sgd(lr = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We specified that the optimizer is the *stochastic gradient descent* and the learning rate is 0.01. Pass the predefined optimizer as a parameter and reduce the *mean squared error* value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=s,loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Fit the model. Update the weights so that the model is a better fit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "4/4 [==============================] - 0s 18ms/step - loss: 34.5006\n"
     ]
    }
   ],
   "source": [
    "model.fit(x, y, epochs=1, batch_size=4, verbose=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `fit` method expects that it receives two NumPy arrays: an input array and the corresponding output array. Note that `epochs` represents the number of times the total dataset is traversed through, and `batch_size` represents the number of data points that need to be considered in an iteration of updating the weights. Furthermore, `verbose` specifies that the output is more detailed, with information about losses (in training and test datasets) as well as the progress of the model training process. Extract the weight values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.03451818,  0.59924877,  0.7735418 ]], dtype=float32),\n",
       " array([-0.08797573, -0.05837556,  0.12796852], dtype=float32),\n",
       " array([[-0.74656653],\n",
       "        [-0.2952211 ],\n",
       "        [ 1.3186555 ]], dtype=float32),\n",
       " array([0.10723891], dtype=float32)]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "El resultado obtenido se corresponde con el asociado al entrenamiento de la red neuronal generada a mano (scratch) en el cuaderno previo!!!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Predict the output for a new set of input using the `predict` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.5088406],\n",
       "       [5.351964 ]], dtype=float32)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = np.array([[5],[6]])\n",
    "model.predict(x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that, while the preceding output is incorrect, the output when we run for 100 epochs is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4/4 [==============================] - 0s 522us/step - loss: 8.4276\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 301us/step - loss: 2.1866\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 236us/step - loss: 0.4040\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 232us/step - loss: 0.1002\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 220us/step - loss: 0.0651\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 215us/step - loss: 0.0607\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 209us/step - loss: 0.0592\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 228us/step - loss: 0.0580\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 224us/step - loss: 0.0567\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 225us/step - loss: 0.0555\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 231us/step - loss: 0.0544\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 222us/step - loss: 0.0532\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 217us/step - loss: 0.0521\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 234us/step - loss: 0.0510\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 257us/step - loss: 0.0499\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 223us/step - loss: 0.0489\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 183us/step - loss: 0.0479\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 247us/step - loss: 0.0469\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 264us/step - loss: 0.0459\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 254us/step - loss: 0.0449\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 292us/step - loss: 0.0440\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 254us/step - loss: 0.0430\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 256us/step - loss: 0.0421\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 262us/step - loss: 0.0412\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 446us/step - loss: 0.0404\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 273us/step - loss: 0.0395\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 204us/step - loss: 0.0387\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 256us/step - loss: 0.0378\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 369us/step - loss: 0.0370\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 282us/step - loss: 0.0363\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 303us/step - loss: 0.0355\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 189us/step - loss: 0.0347\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 236us/step - loss: 0.0340\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 275us/step - loss: 0.0333\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 313us/step - loss: 0.0326\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 238us/step - loss: 0.0319\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 228us/step - loss: 0.0312\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 250us/step - loss: 0.0305\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 239us/step - loss: 0.0299\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 264us/step - loss: 0.0293\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 285us/step - loss: 0.0286\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 292us/step - loss: 0.0280\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 271us/step - loss: 0.0274\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 285us/step - loss: 0.0268\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 374us/step - loss: 0.0263\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 372us/step - loss: 0.0257\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 267us/step - loss: 0.0252\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 312us/step - loss: 0.0246\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 256us/step - loss: 0.0241\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 288us/step - loss: 0.0236\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 233us/step - loss: 0.0231\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 229us/step - loss: 0.0226\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 229us/step - loss: 0.0221\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 385us/step - loss: 0.0216\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 360us/step - loss: 0.0212\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 312us/step - loss: 0.0207\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 329us/step - loss: 0.0203\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 199us/step - loss: 0.0198\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 344us/step - loss: 0.0194\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 261us/step - loss: 0.0190\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 235us/step - loss: 0.0186\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 293us/step - loss: 0.0182\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 252us/step - loss: 0.0178\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 450us/step - loss: 0.0174\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 243us/step - loss: 0.0170\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.0167\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 193us/step - loss: 0.0163\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 247us/step - loss: 0.0160\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 319us/step - loss: 0.0156\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 321us/step - loss: 0.0153\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 366us/step - loss: 0.0149\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 333us/step - loss: 0.0146\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 348us/step - loss: 0.0143\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 339us/step - loss: 0.0140\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 464us/step - loss: 0.0137\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 303us/step - loss: 0.0134\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 276us/step - loss: 0.0131\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 303us/step - loss: 0.0128\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 281us/step - loss: 0.0125\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 236us/step - loss: 0.0123\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 256us/step - loss: 0.0120\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 279us/step - loss: 0.0117\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 272us/step - loss: 0.0115\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 322us/step - loss: 0.0112\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 282us/step - loss: 0.0110\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 198us/step - loss: 0.0108\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 225us/step - loss: 0.0105\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 265us/step - loss: 0.0103\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 240us/step - loss: 0.0101\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 211us/step - loss: 0.0099\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 185us/step - loss: 0.0096\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 196us/step - loss: 0.0094\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 341us/step - loss: 0.0092\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 305us/step - loss: 0.0090\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 255us/step - loss: 0.0088\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 273us/step - loss: 0.0086\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 262us/step - loss: 0.0085\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 301us/step - loss: 0.0083\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 412us/step - loss: 0.0081\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 357us/step - loss: 0.0079\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 9.850092],\n",
       "       [11.777045]], dtype=float32)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y, epochs=100, batch_size=4, verbose=1);\n",
    "model.predict(x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preceding output will match the expected output (which are 10, 12) as we run for even higher number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<link href='http://fonts.googleapis.com/css?family=Alegreya+Sans:100,300,400,500,700,800,900,100italic,300italic,400italic,500italic,700italic,800italic,900italic' rel='stylesheet' type='text/css'>\n",
       "<link href='http://fonts.googleapis.com/css?family=Arvo:400,700,400italic' rel='stylesheet' type='text/css'>\n",
       "<link href='http://fonts.googleapis.com/css?family=PT+Mono' rel='stylesheet' type='text/css'>\n",
       "<link href='http://fonts.googleapis.com/css?family=Shadows+Into+Light' rel='stylesheet' type='text/css'>\n",
       "<link href='http://fonts.googleapis.com/css?family=Nixie+One' rel='stylesheet' type='text/css'>\n",
       "<link href='https://fonts.googleapis.com/css?family=Source+Code+Pro' rel='stylesheet' type='text/css'>\n",
       "<style>\n",
       "\n",
       "@font-face {\n",
       "    font-family: \"Computer Modern\";\n",
       "    src: url('http://mirrors.ctan.org/fonts/cm-unicode/fonts/otf/cmunss.otf');\n",
       "}\n",
       "\n",
       "#notebook_panel { /* main background */\n",
       "    background: rgb(245,245,245);\n",
       "}\n",
       "\n",
       "div.cell { /* set cell width */\n",
       "    width: 750px;\n",
       "}\n",
       "\n",
       "div #notebook { /* centre the content */\n",
       "    background: #fff; /* white background for content */\n",
       "    width: 1000px;\n",
       "    margin: auto;\n",
       "    padding-left: 0em;\n",
       "}\n",
       "\n",
       "#notebook li { /* More space between bullet points */\n",
       "    margin-top:0.8em;\n",
       "}\n",
       "\n",
       "/* draw border around running cells */\n",
       "div.cell.border-box-sizing.code_cell.running { \n",
       "    border: 1px solid #111;\n",
       "}\n",
       "\n",
       "/* Put a solid color box around each cell and its output, visually linking them*/\n",
       "div.cell.code_cell {\n",
       "    background-color: rgb(256,256,256); \n",
       "    border-radius: 0px; \n",
       "    padding: 0.5em;\n",
       "    margin-left:1em;\n",
       "    margin-top: 1em;\n",
       "}\n",
       "\n",
       "div.text_cell_render{\n",
       "    font-family: 'Alegreya Sans' sans-serif;\n",
       "    line-height: 140%;\n",
       "    font-size: 105%;\n",
       "    font-weight: 400;\n",
       "    width:600px;\n",
       "    margin-left:auto;\n",
       "    margin-right:auto;\n",
       "}\n",
       "\n",
       "\n",
       "/* Formatting for header cells */\n",
       ".text_cell_render h1 {\n",
       "    font-family: 'Nixie One', serif;\n",
       "    font-style:regular;\n",
       "    font-weight: 400;    \n",
       "    font-size: 40pt;\n",
       "    line-height: 100%;\n",
       "    color: rgb(0,51,102);\n",
       "    margin-bottom: 0.5em;\n",
       "    margin-top: 0.5em;\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".text_cell_render h2 {\n",
       "    font-family: 'Nixie One', serif;\n",
       "    font-weight: 400;\n",
       "    font-size: 25pt;\n",
       "    line-height: 100%;\n",
       "    color: rgb(0,51,102);\n",
       "    margin-bottom: 0.1em;\n",
       "    margin-top: 0.3em;\n",
       "    display: block;\n",
       "}\t\n",
       "\n",
       ".text_cell_render h3 {\n",
       "    font-family: 'Nixie One', serif;\n",
       "    margin-top:16px;\n",
       "    font-size: 17pt;\n",
       "    font-weight: 600;\n",
       "    margin-bottom: 3px;\n",
       "    font-style: regular;\n",
       "    color: rgb(102,102,0);\n",
       "}\n",
       "\n",
       ".text_cell_render h4 {    /*Use this for captions*/\n",
       "    font-family: 'Nixie One', serif;\n",
       "    font-size: 10pt;\n",
       "    text-align: center;\n",
       "    margin-top: 0em;\n",
       "    margin-bottom: 2em;\n",
       "    font-style: regular;\n",
       "}\n",
       "\n",
       ".text_cell_render h5 {  /*Use this for small titles*/\n",
       "    font-family: 'Nixie One', sans-serif;\n",
       "    font-weight: 400;\n",
       "    font-size: 11pt;\n",
       "    color: rgb(163,0,0);\n",
       "    font-style: italic;\n",
       "    margin-bottom: .1em;\n",
       "    margin-top: 0.8em;\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".text_cell_render h6 { /*use this for copyright note*/\n",
       "    font-family: 'PT Mono', sans-serif;\n",
       "    font-weight: 300;\n",
       "    font-size: 4pt;\n",
       "    line-height: 100%;\n",
       "    color: grey;\n",
       "    margin-bottom: 1px;\n",
       "    margin-top: 1px;\n",
       "}\n",
       "\n",
       ".CodeMirror{\n",
       "    font-family: \"Source Code Pro\";\n",
       "    font-size: 110%;\n",
       "}\n",
       "\n",
       ".alert-box {\n",
       "    padding:10px 10px 10px 36px;\n",
       "    margin:5px;\n",
       "}\n",
       "\n",
       ".success {\n",
       "    color:#666600;\n",
       "    background:rgb(240,242,229);\n",
       "}\n",
       "</style>\n",
       "\n",
       "<script>\n",
       "    MathJax.Hub.Config({\n",
       "                        TeX: {\n",
       "                            extensions: [\"AMSmath.js\"],\n",
       "                            equationNumbers: { autoNumber: \"AMS\", useLabelIds: true}\n",
       "                            },\n",
       "                        tex2jax: {\n",
       "                            inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
       "                            displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
       "                            },\n",
       "                        displayAlign: 'center', // Change this to 'center' to center equations.\n",
       "                        \"HTML-CSS\": {\n",
       "                            styles: {'.MathJax_Display': {\"margin\": 4}}\n",
       "                            }\n",
       "                        });\n",
       "    MathJax.Hub.Queue(\n",
       "                      [\"resetEquationNumbers\", MathJax.InputJax.TeX],\n",
       "                      [\"PreProcess\", MathJax.Hub],\n",
       "                      [\"Reprocess\", MathJax.Hub]\n",
       "                     );\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "css_file = '.././styles/numericalmoocstyle.css'\n",
    "HTML(open(css_file, 'r').read())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Neural_network_working_details.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
